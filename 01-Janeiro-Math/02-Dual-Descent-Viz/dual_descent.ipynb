{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 02: Dual-Descent-Viz - Constrained Optimization\n",
    "\n",
    "**Author:** Davi Bonetto  \n",
    "**Course Module:** 01-Janeiro-Math  \n",
    "\n",
    "## 1. Introduction: The Art of Constrained Optimization\n",
    "\n",
    "In classical optimization, we often seek the global minimum of a function $f(x)$ by following the negative gradient $-\\nabla f(x)$. This is akin to a ball rolling down a hill. However, real-world engineering rarely offers such unbridled freedom. Systems operate under **Constraints**: physical limits, safety bounds, or resource caps.\n",
    "\n",
    "**Real-World Example:**  \n",
    "Consider optimizing a chemical reactor. We wish to **minimize energy consumption** ($f(x)$), but we must strictly constrain the **internal temperature** to be below a critical threshold ($g(x) \\leq 100^\\circ C$) to prevent an explosion. A standard optimizer might minimize cost by letting the temperature rise indefinitely—a catastrophic failure.\n",
    "\n",
    "In this project, we explore **Lagrange Multipliers** and the **Dual Ascent** method to solve such problems, visualizing the trajectory of an agent solving a \"Min-Max\" game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mathematical Formulation\n",
    "\n",
    "We examine a non-convex optimization problem on a 2D plane $(x, y)$.\n",
    "\n",
    "### 2.1 The Primal Objective ($f$)\n",
    "We define the objective function as a hyperbolic paraboloid, often called a **Monkey Saddle** or Saddle Surface. The agent seeks to minimize this path, effectively sliding down to $-\\infty$.\n",
    "\n",
    "$$ f(x, y) = x^2 - y^2 $$\n",
    "\n",
    "### 2.2 The Constraint ($g$)\n",
    "However, we impose a hard geometric constraint. The solution must lie within the **Unit Circle**.\n",
    "\n",
    "$$ g(x, y) = x^2 + y^2 - 1 \\leq 0 $$\n",
    "\n",
    "### 2.3 Why Gradient Descent Fails\n",
    "If we naively applied Gradient Descent ($x_{t+1} = x_t - \\eta \\nabla f$), the agent would follow the steepest descent along the $y$-axis, quickly exiting the unit circle and diverging to negative infinity. The constraint acts as a \"wall\" that standard gradient descent cannot see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Theoretical Framework: The Lagrangian Multiplier Method\n",
    "\n",
    "To reconcile the objective $f(x)$ with the constraint $g(x)$, we construct the **Lagrangian Function** $\\mathcal{L}$. This function converts the constrained problem into an unconstrained game between two variables: the primal vector $x$ and the dual variable $\\lambda$ (Lagrange Multiplier).\n",
    "\n",
    "$$ \\mathcal{L}(x, \\lambda) = f(x) + \\lambda \\cdot g(x) $$\n",
    "\n",
    "### 3.1 The Min-Max Game (Dual Ascent)\n",
    "Our goal is to find the saddle point of the Lagrangian:\n",
    "\n",
    "$$ \\min_x \\max_{\\lambda \\geq 0} \\mathcal{L}(x, \\lambda) $$\n",
    "\n",
    "This implies a competitive dynamic:\n",
    "1.  **The Agent ($x$)** wants to **Minimize** $\\mathcal{L}$. It descends the gradient w.r.t $x$.\n",
    "    $$ x_{t+1} \\leftarrow x_t - \\alpha \\nabla_x \\mathcal{L} $$\n",
    "2.  **The Environment ($\\lambda$)** wants to **Maximize** $\\mathcal{L}$. It ascends the gradient w.r.t $\\lambda$.\n",
    "    $$ \\lambda_{t+1} \\leftarrow \\text{ReLU}(\\lambda_t + \\beta \\nabla_\\lambda \\mathcal{L}) = \\max(0, \\lambda_t + \\beta g(x)) $$\n",
    "\n",
    "If the constraint is violated ($g(x) > 0$), $\\lambda$ increases, heavily penalizing the objective. If the constraint is satisfied, $\\lambda$ drops toward zero.\n",
    "\n",
    "### 3.2 KKT Conditions (Optimality)\n",
    "At the optimal solution $(x^*, \\lambda^*)$, the Karush-Kuhn-Tucker (KKT) conditions must hold. Most notably **Stationarity**: the gradient of the objective must be exactly cancelled out by the gradient of the constraint times $\\lambda$:\n",
    "$$ \\nabla f(x^*) + \\lambda^* \\nabla g(x^*) = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- 2.1 Define Functions ---\n",
    "\n",
    "def f(x, y):\n",
    "    \"\"\"Objective: Saddle Surface\"\"\"\n",
    "    return x**2 - y**2\n",
    "\n",
    "def grad_f(x, y):\n",
    "    \"\"\"Gradient of f w.r.t [x, y]\"\"\"\n",
    "    df_dx = 2 * x\n",
    "    df_dy = -2 * y\n",
    "    return np.array([df_dx, df_dy])\n",
    "\n",
    "def g(x, y):\n",
    "    \"\"\"Constraint: Inside Unit Circle (x^2 + y^2 - 1 <= 0)\"\"\"\n",
    "    return x**2 + y**2 - 1\n",
    "\n",
    "def grad_g(x, y):\n",
    "    \"\"\"Gradient of g w.r.t [x, y]\"\"\"\n",
    "    dg_dx = 2 * x\n",
    "    dg_dy = 2 * y\n",
    "    return np.array([dg_dx, dg_dy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementation: The Dual Descent Engine\n",
    "\n",
    "We implement the `DualDescentOptimizer` class. Note the distinct learning rates for the primal ($\\{x, y\\}$) and dual ($\\{\\lambda\\}$) updates. Tuning these rates is critical: if $\\lambda$ grows too fast, the system oscillates; if too slow, the constraint is violated for too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DualDescentOptimizer:\n",
    "    def __init__(self, learning_rate_primal=0.05, learning_rate_dual=0.1):\n",
    "        self.lr_x = learning_rate_primal\n",
    "        self.lr_lambda = learning_rate_dual\n",
    "        self.history = []\n",
    "        \n",
    "    def optimize(self, start_x, start_y, iterations=200):\n",
    "        # Initialize variables\n",
    "        x, y = start_x, start_y\n",
    "        lam = 0.0 # Initial Lagrange Multiplier (usually 0)\n",
    "        \n",
    "        self.history = []\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            # 1. Compute Gradients\n",
    "            gf = grad_f(x, y)\n",
    "            gg = grad_g(x, y)\n",
    "            constraint_val = g(x, y)\n",
    "            \n",
    "            # 2. Lagrangian Gradient w.r.t x (Primal step)\n",
    "            # L = f + lambda * g\n",
    "            # dL/dx = df/dx + lambda * dg/dx\n",
    "            grad_L_x = gf + lam * gg\n",
    "            \n",
    "            # 3. Update primal variables (Gradient Descent)\n",
    "            # x_new = x - lr * grad_L_x\n",
    "            x_new = x - self.lr_x * grad_L_x[0]\n",
    "            y_new = y - self.lr_x * grad_L_x[1]\n",
    "            \n",
    "            # 4. Update dual variable (Gradient Ascent)\n",
    "            # lambda needs to increase if constraint is violated (g > 0)\n",
    "            # And we project to >= 0 (KKT condition)\n",
    "            lam_new = lam + self.lr_lambda * constraint_val\n",
    "            lam_new = max(0.0, lam_new)\n",
    "            \n",
    "            # Store history\n",
    "            z_val = f(x, y)\n",
    "            self.history.append({\n",
    "                'step': i,\n",
    "                'x': x, 'y': y, 'z': z_val,\n",
    "                'lambda': lam,\n",
    "                'constraint': constraint_val\n",
    "            })\n",
    "            \n",
    "            # Update state\n",
    "            x, y, lam = x_new, y_new, lam_new\n",
    "            \n",
    "        return self.history\n",
    "\n",
    "# --- Run Simulation ---\n",
    "# Start OUTSIDE the circle at (1.5, 0.0) where objective x^2 - y^2 is 2.25\n",
    "optimizer = DualDescentOptimizer(learning_rate_primal=0.02, learning_rate_dual=0.1)\n",
    "history = optimizer.optimize(start_x=1.5, start_y=0.1, iterations=150)\n",
    "\n",
    "print(f\"Final Position: ({history[-1]['x']:.3f}, {history[-1]['y']:.3f})\")\n",
    "print(f\"Final Constraint Value: {history[-1]['constraint']:.3f} (Should be <= 0)\")\n",
    "print(f\"Final Lambda: {history[-1]['lambda']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visual Analysis (Plotly)\n",
    "\n",
    "We employ a 3D interactive visualization to observe the dynamics.\n",
    "- **Surface**: The objective function terrain.\n",
    "- **Cylinder/Mesh**: The boundary of the feasible region.\n",
    "- **Path**: The agent's trajectory.\n",
    "\n",
    "Pay attention to how the agent starts outside, is pulled in, and then \"surfs\" along the boundary wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare Data for Plotting\n",
    "traj_x = [h['x'] for h in history]\n",
    "traj_y = [h['y'] for h in history]\n",
    "traj_z = [h['z'] for h in history]\n",
    "\n",
    "# 1. Surface Data (The Saddle)\n",
    "x_range = np.linspace(-2, 2, 50)\n",
    "y_range = np.linspace(-2, 2, 50)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "Z = f(X, Y)\n",
    "\n",
    "# 2. Constraint Data (The Cylinder Wall x^2 + y^2 = 1)\n",
    "theta = np.linspace(0, 2*np.pi, 50)\n",
    "z_cyl = np.linspace(-4, 4, 10)\n",
    "THETA, Z_CYL = np.meshgrid(theta, z_cyl)\n",
    "X_CYL = np.cos(THETA)\n",
    "Y_CYL = np.sin(THETA)\n",
    "\n",
    "# --- Plotly Figure ---\n",
    "fig = go.Figure()\n",
    "\n",
    "# A. The Saddle Surface\n",
    "fig.add_trace(go.Surface(z=Z, x=X, y=Y, colorscale='Viridis', opacity=0.7, name='Objective'))\n",
    "\n",
    "# B. The Constraint Wall\n",
    "# We construct this using Mesh3d or just lines. Surface is easier here.\n",
    "fig.add_trace(go.Surface(z=Z_CYL, x=X_CYL, y=Y_CYL, showscale=False, opacity=0.3, colorscale='Greys', name='Constraint'))\n",
    "\n",
    "# C. The Trajectory\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=traj_x, y=traj_y, z=traj_z,\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=4, color=list(range(len(traj_x))), colorscale='Bluered', showscale=False),\n",
    "    line=dict(color='black', width=3),\n",
    "    name='Agent Path'\n",
    "))\n",
    "\n",
    "# D. Start and End points\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[traj_x[0]], y=[traj_y[0]], z=[traj_z[0]],\n",
    "    mode='markers', marker=dict(size=8, color='green'), name='Start'\n",
    "))\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[traj_x[-1]], y=[traj_y[-1]], z=[traj_z[-1]],\n",
    "    mode='markers', marker=dict(size=8, color='red'), name='End'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Dual Descent: Saddle Point Optimization with Constraints\",\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='f(x,y)',\n",
    "        aspectmode='cube'\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Geometric Conclusion\n",
    "\n",
    "Observing the graph generated above, we witness the essence of **Constrained Optimization**.\n",
    "\n",
    "1.  **Escape Attempt:** Initially, the agent (green dot) rushes down the slope, driven by $\\nabla f$, violating the boundary.\n",
    "2.  **Correction:** As $g(x) > 0$, the dual variable $\\lambda$ spikes. This adds a gradient component $\\lambda \\nabla g$ pointing back towards the center.\n",
    "3.  **Equilibrium:** The agent settles at the boundary (red dot). It wants to go lower (outward), but the penalty is too high. It has found the **Saddle Point** of the Lagrangian—stable in $x$, stable in $\\lambda$.\n",
    "\n",
    "This mechanic underpins modern Support Vector Machines (SVMs) and Constrained Deep Learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
