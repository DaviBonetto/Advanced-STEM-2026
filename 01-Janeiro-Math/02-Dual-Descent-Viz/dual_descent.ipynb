{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 02: Dual-Descent-Viz - Constrained Optimization\n",
    "\n",
    "**Author:** Davi Bonetto  \n",
    "\n",
    "## 1. Theoretical Foundations\n",
    "\n",
    "### 1.1 The Primal Problem\n",
    "Standard Gradient Descent finds a local minimum of an unconstrained function $f(x)$. However, in the real world (and in Deep Learning), variables are often constrained. \n",
    "\n",
    "We aim to minimize a function $f(x)$ subject to an inequality constraint $g(x) \\leq 0$:\n",
    "\n",
    "$$ \\min_x f(x) \\quad \\text{subject to} \\quad g(x) \\leq 0 $$\n",
    "\n",
    "### 1.2 The Lagrangian & Dual Ascent\n",
    "We convert this constrained problem into an unconstrained \"Min-Max\" game using the **Lagrangian Function**:\n",
    "\n",
    "$$ \\mathcal{L}(x, \\lambda) = f(x) + \\lambda g(x) $$\n",
    "\n",
    "Here, $\\lambda$ (Lambda) is the **Lagrange Multiplier**. It acts as a \"price\" or \"penalty\" for violating the constraint.\n",
    "\n",
    "**The Logic:**\n",
    "1.  **Primal Descent (Minimize $x$):** The agent tries to minimize the total cost (Objective + Penalty). If $\\lambda$ is high, the agent is forced to reduce $g(x)$.\n",
    "    $$ x_{t+1} = x_t - \\alpha \\nabla_x \\mathcal{L} $$\n",
    "\n",
    "2.  **Dual Ascent (Maximize $\\lambda$):** The system tries to maximize the penalty. If the agent violates the constraint ($g(x) > 0$), $\\lambda$ shoots up, making the violation expensive. If satisfied, $\\lambda$ drops to 0.\n",
    "    $$ \\lambda_{t+1} = \\text{ReLU}(\\lambda_t + \\beta \\nabla_\\lambda \\mathcal{L}) = \\text{ReLU}(\\lambda_t + \\beta g(x)) $$\n",
    "\n",
    "### 1.3 KKT Conditions\n",
    "At the optimal point $(x^*, \\lambda^*)$, the Karush-Kuhn-Tucker (KKT) conditions hold:\n",
    "- **Stationarity:** $\\nabla f(x^*) + \\lambda^* \\nabla g(x^*) = 0$ (Forces balance).\n",
    "- **Primal Feasibility:** $g(x^*) \\leq 0$.\n",
    "- **Dual Feasibility:** $\\lambda^* \\geq 0$.\n",
    "- **Complementary Slackness:** $\\lambda^* g(x^*) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Problem Setup\n",
    "\n",
    "We optimize a 2D agent $(x, y)$.\n",
    "\n",
    "**Objective ($f$):** A non-convex \"Saddle\" function. The agent wants to slide down to $-\\infty$, but...\n",
    "$$ f(x, y) = x^2 - y^2 $$\n",
    "\n",
    "**Constraint ($g$):** The agent must stay inside the Unit Circle.\n",
    "$$ g(x, y) = x^2 + y^2 - 1 \\leq 0 $$\n",
    "\n",
    "The generic minimum of $f$ is at $(0, \\pm \\infty)$. But constrained to the circle, the minimums are at $(0, 1)$ and $(0, -1)$ with value $-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- 2.1 Define Functions ---\n",
    "\n",
    "def f(x, y):\n",
    "    \"\"\"Objective: Saddle Surface\"\"\"\n",
    "    return x**2 - y**2\n",
    "\n",
    "def grad_f(x, y):\n",
    "    \"\"\"Gradient of f w.r.t [x, y]\"\"\"\n",
    "    df_dx = 2 * x\n",
    "    df_dy = -2 * y\n",
    "    return np.array([df_dx, df_dy])\n",
    "\n",
    "def g(x, y):\n",
    "    \"\"\"Constraint: Inside Unit Circle (x^2 + y^2 - 1 <= 0)\"\"\"\n",
    "    return x**2 + y**2 - 1\n",
    "\n",
    "def grad_g(x, y):\n",
    "    \"\"\"Gradient of g w.r.t [x, y]\"\"\"\n",
    "    dg_dx = 2 * x\n",
    "    dg_dy = 2 * y\n",
    "    return np.array([dg_dx, dg_dy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The 'DualDescent' Engine\n",
    "\n",
    "We calculate the gradients of the Lagrangian:\n",
    "$$ \\nabla_x \\mathcal{L} = \\nabla f(x) + \\lambda \\nabla g(x) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualDescentOptimizer:\n",
    "    def __init__(self, learning_rate_primal=0.05, learning_rate_dual=0.1):\n",
    "        self.lr_x = learning_rate_primal\n",
    "        self.lr_lambda = learning_rate_dual\n",
    "        self.history = []\n",
    "        \n",
    "    def optimize(self, start_x, start_y, iterations=200):\n",
    "        # Initialize variables\n",
    "        x, y = start_x, start_y\n",
    "        lam = 0.0 # Initial Lagrange Multiplier (usually 0)\n",
    "        \n",
    "        self.history = []\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            # 1. Compute Gradients\n",
    "            gf = grad_f(x, y)\n",
    "            gg = grad_g(x, y)\n",
    "            constraint_val = g(x, y)\n",
    "            \n",
    "            # 2. Lagrangian Gradient w.r.t x (Primal step)\n",
    "            # L = f + lambda * g\n",
    "            # dL/dx = df/dx + lambda * dg/dx\n",
    "            grad_L_x = gf + lam * gg\n",
    "            \n",
    "            # 3. Update primal variables (Gradient Descent)\n",
    "            # x_new = x - lr * grad_L_x\n",
    "            x_new = x - self.lr_x * grad_L_x[0]\n",
    "            y_new = y - self.lr_x * grad_L_x[1]\n",
    "            \n",
    "            # 4. Update dual variable (Gradient Ascent)\n",
    "            # lambda needs to increase if constraint is violated (g > 0)\n",
    "            # And we project to >= 0 (KKT condition)\n",
    "            lam_new = lam + self.lr_lambda * constraint_val\n",
    "            lam_new = max(0.0, lam_new)\n",
    "            \n",
    "            # Store history\n",
    "            z_val = f(x, y)\n",
    "            self.history.append({\n",
    "                'step': i,\n",
    "                'x': x, 'y': y, 'z': z_val,\n",
    "                'lambda': lam,\n",
    "                'constraint': constraint_val\n",
    "            })\n",
    "            \n",
    "            # Update state\n",
    "            x, y, lam = x_new, y_new, lam_new\n",
    "            \n",
    "        return self.history\n",
    "\n",
    "# --- Run Simulation ---\n",
    "# Start OUTSIDE the circle at (1.5, 0.0) where objective x^2 - y^2 is 2.25\n",
    "optimizer = DualDescentOptimizer(learning_rate_primal=0.02, learning_rate_dual=0.1)\n",
    "history = optimizer.optimize(start_x=1.5, start_y=0.1, iterations=150)\n",
    "\n",
    "print(f\"Final Position: ({history[-1]['x']:.3f}, {history[-1]['y']:.3f})\")\n",
    "print(f\"Final Constraint Value: {history[-1]['constraint']:.3f} (Should be <= 0)\")\n",
    "print(f\"Final Lambda: {history[-1]['lambda']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Visualization\n",
    "\n",
    "We visualize the agent \"surfing\" the saddle point while hitting the invisible cylindrical wall of the constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data for Plotting\n",
    "traj_x = [h['x'] for h in history]\n",
    "traj_y = [h['y'] for h in history]\n",
    "traj_z = [h['z'] for h in history]\n",
    "\n",
    "# 1. Surface Data (The Saddle)\n",
    "x_range = np.linspace(-2, 2, 50)\n",
    "y_range = np.linspace(-2, 2, 50)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "Z = f(X, Y)\n",
    "\n",
    "# 2. Constraint Data (The Cylinder Wall x^2 + y^2 = 1)\n",
    "theta = np.linspace(0, 2*np.pi, 50)\n",
    "z_cyl = np.linspace(-4, 4, 10)\n",
    "THETA, Z_CYL = np.meshgrid(theta, z_cyl)\n",
    "X_CYL = np.cos(THETA)\n",
    "Y_CYL = np.sin(THETA)\n",
    "\n",
    "# --- Plotly Figure ---\n",
    "fig = go.Figure()\n",
    "\n",
    "# A. The Saddle Surface\n",
    "fig.add_trace(go.Surface(z=Z, x=X, y=Y, colorscale='Viridis', opacity=0.7, name='Objective'))\n",
    "\n",
    "# B. The Constraint Wall\n",
    "# We construct this using Mesh3d or just lines. Surface is easier here.\n",
    "fig.add_trace(go.Surface(z=Z_CYL, x=X_CYL, y=Y_CYL, showscale=False, opacity=0.3, colorscale='Greys', name='Constraint'))\n",
    "\n",
    "# C. The Trajectory\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=traj_x, y=traj_y, z=traj_z,\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=4, color=list(range(len(traj_x))), colorscale='Bluered', showscale=False),\n",
    "    line=dict(color='black', width=3),\n",
    "    name='Agent Path'\n",
    "))\n",
    "\n",
    "# D. Start and End points\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[traj_x[0]], y=[traj_y[0]], z=[traj_z[0]],\n",
    "    mode='markers', marker=dict(size=8, color='green'), name='Start'\n",
    "))\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[traj_x[-1]], y=[traj_y[-1]], z=[traj_z[-1]],\n",
    "    mode='markers', marker=dict(size=8, color='red'), name='End'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Dual Descent: Saddle Point Optimization with Constraints\",\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='f(x,y)',\n",
    "        aspectmode='cube'\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
